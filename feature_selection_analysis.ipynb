{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b03926b",
   "metadata": {},
   "source": [
    "# Feature Selection Analysis\n",
    "\n",
    "This notebook contains the analysis from feature_selection_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "def load_data(filename='sample_openpowerlifting.csv'):\n",
    "    data = pd.read_csv(filename)\n",
    "    \n",
    "    # Select numerical features only for this analysis\n",
    "    numerical_features = ['Age', 'BodyweightKg', 'WeightClassKg', 'Best3SquatKg', \n",
    "                         'Best3BenchKg', 'Best3DeadliftKg', 'TotalKg', 'Wilks']\n",
    "    \n",
    "    # Create feature matrix X\n",
    "    X = data[numerical_features].copy()\n",
    "    \n",
    "    # Convert columns to numeric, replacing errors with NaN\n",
    "    for col in X.columns:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "    \n",
    "    # Create target variable y (Sex: M=0, F=1)\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(data['Sex'])\n",
    "    \n",
    "    # Handle any missing values\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bafea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mutual_info(X, y):\n",
    "    # Calculate mutual information scores\n",
    "    mi_scores = mutual_info_classif(X, y)\n",
    "    \n",
    "    # Create a dataframe of features and their MI scores\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': mi_scores\n",
    "    }).drop_duplicates()\n",
    "    \n",
    "    # Sort by importance\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== Mutual Information Feature Selection ===\")\n",
    "    print(\"All features and their Mutual Information scores:\")\n",
    "    print(feature_importance.to_string(index=False))\n",
    "    \n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rf_importance(X, y):\n",
    "    # Train Random Forest and get feature importances\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Create a dataframe of features and their importance scores\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).drop_duplicates()\n",
    "    \n",
    "    # Sort by importance\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== Random Forest Feature Selection ===\")\n",
    "    print(\"All features and their importance scores:\")\n",
    "    print(feature_importance.to_string(index=False))\n",
    "    \n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dcf221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, selected_features, method_name):\n",
    "    # Create dataset with selected features\n",
    "    X_selected = X[selected_features]\n",
    "    \n",
    "    # Initialize Random Forest model\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(rf, X_selected, y, cv=5)\n",
    "    \n",
    "    print(f\"\\nRandom Forest Cross-validation results using top 5 {method_name} features:\")\n",
    "    print(f\"Features used: {selected_features}\")\n",
    "    print(f\"Individual CV scores: {cv_scores}\")\n",
    "    print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    \n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499fc39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(mi_importance, rf_importance):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot both feature importance methods\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(5), mi_importance['importance'].head())\n",
    "    plt.xticks(range(5), mi_importance['feature'].head(), rotation=45)\n",
    "    plt.title('Top 5 Features (Mutual Information)')\n",
    "    plt.ylabel('Mutual Information Score')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(5), rf_importance['importance'].head())\n",
    "    plt.xticks(range(5), rf_importance['feature'].head(), rotation=45)\n",
    "    plt.title('Top 5 Features (Random Forest)')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_selection_comparison.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073fed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    X, y = load_data()\n",
    "    print(\"Original dataset shape:\", X.shape)\n",
    "    \n",
    "    # 1. Mutual Information Analysis\n",
    "    mi_importance = analyze_mutual_info(X, y)\n",
    "    top_5_mi = mi_importance['feature'].head().tolist()\n",
    "    mi_cv_scores = evaluate_model(X, y, top_5_mi, \"Mutual Information\")\n",
    "    \n",
    "    # 2. Random Forest Feature Importance Analysis\n",
    "    rf_importance = analyze_rf_importance(X, y)\n",
    "    top_5_rf = rf_importance['feature'].head().tolist()\n",
    "    rf_cv_scores = evaluate_model(X, y, top_5_rf, \"Random Forest\")\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_comparison(mi_importance, rf_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
