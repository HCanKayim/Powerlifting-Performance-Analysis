{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc42d6f1",
   "metadata": {},
   "source": [
    "# Classification Analysis\n",
    "\n",
    "This notebook contains the analysis from classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"sample_openpowerlifting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing essential data\n",
    "df_clean = df.dropna(subset=['Wilks', 'Age', 'BodyweightKg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c201367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target: 1 if Wilks score above median\n",
    "median_wilks = df_clean['Wilks'].median()\n",
    "df_clean = df_clean.copy()\n",
    "df_clean['StrongLifter'] = (df_clean['Wilks'] > median_wilks).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "print(\"\\nClass Balance Check:\")\n",
    "class_counts = df_clean['StrongLifter'].value_counts()\n",
    "print(\"Class distribution before balancing:\")\n",
    "print(class_counts)\n",
    "print(f\"Class 0: {class_counts[0]} instances ({class_counts[0]/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"Class 1: {class_counts[1]} instances ({class_counts[1]/len(df_clean)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592edaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance dataset by downsampling majority class\n",
    "class_0 = df_clean[df_clean['StrongLifter'] == 0]\n",
    "class_1 = df_clean[df_clean['StrongLifter'] == 1]\n",
    "min_class_size = min(len(class_0), len(class_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd611088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample majority class\n",
    "if len(class_0) > len(class_1):\n",
    "    class_0 = class_0.sample(n=min_class_size, random_state=42)\n",
    "else:\n",
    "    class_1 = class_1.sample(n=min_class_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine balanced classes\n",
    "df_balanced = pd.concat([class_0, class_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6980df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClass distribution after balancing:\")\n",
    "balanced_counts = df_balanced['StrongLifter'].value_counts()\n",
    "print(f\"Class 0: {balanced_counts[0]} instances ({balanced_counts[0]/len(df_balanced)*100:.1f}%)\")\n",
    "print(f\"Class 1: {balanced_counts[1]} instances ({balanced_counts[1]/len(df_balanced)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns\n",
    "features = ['Age', 'BodyweightKg', 'Sex', 'Equipment', 'Event']\n",
    "target = 'StrongLifter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d31f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df_features = pd.get_dummies(df_balanced[features], drop_first=True)\n",
    "df_target = df_balanced[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a17aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbaeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'KNN Classifier': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "classification_results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    classification_results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test set performance\n",
    "print(\"\\nClassification Results (Using Balanced Dataset)\")\n",
    "print(f\"Median Wilks Score: {median_wilks:.2f}\")\n",
    "for model_name, metrics in classification_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Accuracy:  {metrics['Accuracy']:.3f}\")\n",
    "    print(f\"  Precision: {metrics['Precision']:.3f}\")\n",
    "    print(f\"  Recall:    {metrics['Recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bf292",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n10-Fold Cross-Validation Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores = cross_val_score(log_reg, df_features, df_target, cv=10, scoring='accuracy')\n",
    "rf_scores = cross_val_score(rf_clf, df_features, df_target, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbf56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print CV results\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(\"Fold Accuracies:\", [f\"{score:.3f}\" for score in log_scores])\n",
    "print(f\"Average Accuracy: {np.mean(log_scores):.3f} (±{np.std(log_scores):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRandom Forest:\")\n",
    "print(\"Fold Accuracies:\", [f\"{score:.3f}\" for score in rf_scores])\n",
    "print(f\"Average Accuracy: {np.mean(rf_scores):.3f} (±{np.std(rf_scores):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03512c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting Analysis\n",
    "print(\"\\nOverfitting Analysis:\")\n",
    "for name, clf in {'Logistic Regression': log_reg, 'Random Forest': rf_clf}.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Training Accuracy: {train_score:.3f}\")\n",
    "    print(f\"  Test Accuracy:     {test_score:.3f}\")\n",
    "    print(f\"  Difference:        {train_score - test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f396420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis of Wilks score distribution\n",
    "print(\"\\nWilks Score Distribution by Sex:\")\n",
    "print(df_clean.groupby('Sex')['Wilks'].describe())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
